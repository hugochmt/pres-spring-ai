---
hideInToc: true
theme: default
layout: image-right
backgroundSize: 90%
fonts:
  sans: 'Montserrat'
image: resources/img/bg.png
---

# **Spring AI**

### Faire discuter son application avec un LLM

---
hideInToc: true
layout: intro
---

# Sommaire

<Toc columns="2"/>


---

# Contexte

- Essor de l'utilisation des IAs g√©n√©ratives depuis quelques ann√©es (ChatGPT, Claude, Midjourney ...)
- R√©volution du prompt : on peut d√©finir sa demande en langage naturel
- Lancement de frameworks et librairies pour faciliter l'utilisation des LLMs, autour des APIs OpenAI, Google...
- Ex: [langchain4j](https://github.com/langchain4j/langchain4j)

---

# Quelques d√©finitions

### **üß† Mod√®le**

- Un mod√®le est un programme d‚Äôintelligence artificielle qui a appris √† accomplir une t√¢che √† partir de donn√©es
- Exemple : comprendre du texte, g√©n√©rer des images, traduire...

### **üó£Ô∏è LLM (Large Language Model)**

- Mod√®le de langage de tr√®s grande taille, entra√Æn√© sur d‚Äôimmenses volumes de textes pour comprendre et g√©n√©rer du
  langage naturel.
- Exemple : GPT-3, GPT-4, Mistral_7B (ChatGPT ‚â† GPT-3)

---
hideInToc: true
---

# Quelques d√©finitions

### **üìù Prompt**

- Texte que l‚Äôon envoie au mod√®le pour qu‚Äôil fasse quelque chose.
- Exemple :

```bash
  Prompt : "√âcris une courte histoire sur un chat qui vole."
  R√©ponse du mod√®le : "Il √©tait une fois un chat qui avait des ailes argent√©es..."
```

### **üìÅ Context / Contexte**

Ensemble d‚Äôinformations fournies au mod√®le au moment o√π il doit g√©n√©rer une r√©ponse.

- Le contexte est stateless ‚Üí chaque requ√™te doit inclure les infos utiles.
- Peut inclure : historique de conversation, documents, r√¥le utilisateur, etc.

---

# Quelques d√©finitions

### **üß© Token**

- Un token est une unit√© de texte comprise par un mod√®le. Ce n‚Äôest pas forc√©ment un mot entier : cela peut √™tre un
  morceau de mot, une ponctuation, etc.

### **üå°Ô∏è Temp√©rature**

- La temp√©rature est un param√®tre qui contr√¥le le degr√© de cr√©ativit√© ou de randomness dans la g√©n√©ration de texte par
  un mod√®le de langage.

---

# Disclaimer

- Ceci n'est pas une presentation sur le fonctionnement de l'IA
- Domaine qui √©volue vite (notions obsel√®tes dans quelques temps ?)

---
layout: image-right
image: resources/img/img.png
backgroundSize: contain
---

# üå± Spring AI

- Module pour l'IA G√©n√©rative
- Support multi-providers : OpenAI, Google, Mistral, Ollama ...
- Support multi-mod√®les
- Features
    - ChatAPI
    - Tools calling
    - MCP
    - ...
- v1.0.0 mai 2025

---

# üí¨ Chat API

- API fluent pour la communication avec un mod√®le
- system
- user

---
hideInToc: true
layout: center
---

<style>
h1 {
  font-weight: bold;
}
</style>

# Let's code !

---
layout: image-right
image: resources/img/structured_output.png
backgroundSize: contain
---

# üóÇÔ∏è Structured output

- Pas besoin de fournir le mod√®le en entr√©e (spring le fait pour nous)
- Permet de mapper le r√©sultat vers un objet typ√©
- Possibilit√© d'impl√©menter des converter custom
- ‚ö† Tente de peupler l'objet quoi qu'il arrive (pas d'exception lanc√©e) pr√©voir des fallback

---

# Tool Calling

- Lecture/√©criture
- Evidemment, attention

---

# Advisors
- M√©moire
- Monitoring
  - SimpleLoggerAdvisor

---

# ü¶ô Ollama

> Docker for LLMs

- Mod√®les sur Hugging Face
- Int√©gration avec Spring AI
- Possibilit√© de auto-pull model
- ‚ö† Certains mod√®les peuvent mal supporter les structured output
- Docker Model Runner

---

# üì∂ MCP

- > Like an USB port for AI applications
- Protocole pour fournir du contexte
- SDK multi-langage (Java, TypeScript, Python ...)
- Fetch page web, API, file system, bases de donn√©es...

---

# üõ° S√©curit√©

- protection de prompt
-

---

# Cas d'usage r√©els ?

- Chat bot, aide utilisateur
- Classification de donn√©es
- ...

---

# Et aussi...

- observabilit√©
- Recherche s√©mantique
- RAG (Retrieval Augmented Generation)
